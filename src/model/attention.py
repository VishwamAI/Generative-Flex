import math
import torch
import torch.nn as nn
Efficient
"""Flash Attention Implementation for Generative-Flex...."""
(nn.Module):
"""attention implementation using flash attention algorithm...."""